import os
import subprocess

import openai
import torch
from dotenv import load_dotenv
from vosk_tts import Synth, Model as ttsModel
from yandex_cloud_ml_sdk import YCloudML

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

yandex_api_key = os.getenv("YANDEX_API_KEY")
yandex_folder_id = os.getenv("YANDEX_FOLDER_ID")

SAMPLE_RATE = 16000


def get_transcription_gpu(audio_path: str) -> str:
    """
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç GPU-–≤–µ—Ä—Å–∏—é Kaldi –∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è vosk-api-gpu
    """
    process = subprocess.Popen(
        ["./vosk-api-gpu/bin/transcriber", "--model", "path_to_model", "--audio", audio_path],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE
    )
    out, err = process.communicate()
    if process.returncode != 0:
        raise RuntimeError(f"–û—à–∏–±–∫–∞ –≤ transcriber: {err.decode()}")

    return out.decode().strip()


def summarize_objects_from_text_request_openai(prompt):
    system_promt = "You are an intermediate module for a robot, responsible for processing natural-language voice commands from users. Your primary function is to extract concrete, visually detectable objects that the robot should identify and approach.\
        Follow these exact instructions:\
        üîç OBJECT EXTRACTION\
        Identify physical objects explicitly mentioned in the input.\
        Retain only descriptive attributes that are:\
        Objective\
        Visually observable (e.g., color, shape, size)\
        Remove all subjective, emotional, or personal descriptors, such as:\
        ‚Äúmy favorite‚Äù, ‚Äúbeautiful‚Äù, ‚Äúscary‚Äù, ‚Äúfunny‚Äù, etc.\
        Example:\
        Input: 'Find my favorite red cat'\
        Output: –∫–æ—Ç;cat (‚Äúred‚Äù is ignored if not essential for visual identification or is subjective in context)\
        üåê TRANSLATION FORMAT\
        For each object, output the pair:\
        [original phrase];[English translation]\
        Separate each object with a comma.\
        ‚úÖ OUTPUT RULES\
        Use only essential adjectives: colors, shapes, sizes.\
        Each item must be formatted as:\
        [original adjective + noun];[translated adjective + noun]\
        If no valid attributes exist, output just the noun:\
        –∫–æ—à–∫–∞;cat\
        üß† EXAMPLES\
        User command: '–ü–æ–∫–∞–∂–∏ –º–æ—é –ª—é–±–∏–º—É—é –∫—Ä–∞—Å–Ω—É—é –ø–∏—Ä–∞–º–∏–¥—É –∏ –æ–≥—Ä–æ–º–Ω—É—é –±—É—Ç—ã–ª–∫—É –≤–æ–¥—ã'\
        ‚Üí Output: –∫—Ä–∞—Å–Ω–∞—è –ø–∏—Ä–∞–º–∏–¥–∞;red pyramid, –±–æ–ª—å—à–∞—è –±—É—Ç—ã–ª–∫–∞;large bottle'\
        User command: '–ù–∞–π–¥–∏ —Å—Ç—Ä–∞—à–Ω—É—é –∏–≥—Ä—É—à–∫—É –∏ –∑–µ–ª—ë–Ω—ã–π –∫—É–±'\
        ‚Üí Output: –∏–≥—Ä—É—à–∫–∞;toy, –∑–µ–ª—ë–Ω—ã–π –∫—É–±;green cube\
        User command: '–ü–æ–¥–æ–π–¥–∏ –∫ –º–æ–µ–º—É –º–∏–ª–æ–º—É —Å–∏–Ω–µ–º—É –≤–µ–¥—Ä—É –∏ –ª—é–±–∏–º–æ–º—É —Å—Ç–æ–ª—É'\
        ‚Üí Output: —Å–∏–Ω–µ–µ –≤–µ–¥—Ä–æ;blue bucket, —Å—Ç–æ–ª;table\
        This format ensures clarity, consistency, and high compatibility with downstream object detection systems.\
        Let me know if you'd like this as a structured JSON response format or used in a live NLP pipeline."
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4.1-mini",
            messages=[
                {
                    "role": "system",
                    "content": system_promt,
                },
                {
                    "role": "user",
                    "content": prompt,
                },
            ],
        )
        return list(map(lambda x: x.split(";"), response.choices[0].message.content.split(", ")))

    except Exception as e:
        return f"An error occurred: {e}"


def summarize_objects_from_text_request_yandex(prompt: str) -> str:
    sdk = YCloudML(
        folder_id=yandex_folder_id,
        auth=yandex_api_key
    )

    model = sdk.models.completions("yandexgpt", model_version="rc")
    model = model.configure(temperature=0.3)
    try:
        result = model.run(
            [
                {"role": "system", "text": "You are an intermediate module for a robot, responsible for processing natural-language voice commands from users. Your primary function is to extract concrete, visually detectable objects that the robot should identify and approach.\
                Follow these exact instructions:\
                üîç OBJECT EXTRACTION\
                Identify physical objects explicitly mentioned in the input.\
                Retain only descriptive attributes that are:\
                Objective\
                Visually observable (e.g., color, shape, size)\
                Remove all subjective, emotional, or personal descriptors, such as:\
                ‚Äúmy favorite‚Äù, ‚Äúbeautiful‚Äù, ‚Äúscary‚Äù, ‚Äúfunny‚Äù, etc.\
                Example:\
                Input: 'Find my favorite red cat'\
                Output: –∫–æ—Ç;cat (‚Äúred‚Äù is ignored if not essential for visual identification or is subjective in context)\
                üåê TRANSLATION FORMAT\
                For each object, output the pair:\
                [original phrase];[English translation]\
                Separate each object with a comma.\
                ‚úÖ OUTPUT RULES\
                Use only essential adjectives: colors, shapes, sizes.\
                Each item must be formatted as:\
                [original adjective + noun];[translated adjective + noun]\
                If no valid attributes exist, output just the noun:\
                –∫–æ—à–∫–∞;cat\
                üß† EXAMPLES\
                User command: '–ü–æ–∫–∞–∂–∏ –º–æ—é –ª—é–±–∏–º—É—é –∫—Ä–∞—Å–Ω—É—é –ø–∏—Ä–∞–º–∏–¥—É –∏ –æ–≥—Ä–æ–º–Ω—É—é –±—É—Ç—ã–ª–∫—É –≤–æ–¥—ã'\
                ‚Üí Output: –∫—Ä–∞—Å–Ω–∞—è –ø–∏—Ä–∞–º–∏–¥–∞;red pyramid, –±–æ–ª—å—à–∞—è –±—É—Ç—ã–ª–∫–∞;large bottle'\
                User command: '–ù–∞–π–¥–∏ —Å—Ç—Ä–∞—à–Ω—É—é –∏–≥—Ä—É—à–∫—É –∏ –∑–µ–ª—ë–Ω—ã–π –∫—É–±'\
                ‚Üí Output: –∏–≥—Ä—É—à–∫–∞;toy, –∑–µ–ª—ë–Ω—ã–π –∫—É–±;green cube\
                User command: '–ü–æ–¥–æ–π–¥–∏ –∫ –º–æ–µ–º—É –º–∏–ª–æ–º—É —Å–∏–Ω–µ–º—É –≤–µ–¥—Ä—É –∏ –ª—é–±–∏–º–æ–º—É —Å—Ç–æ–ª—É'\
                ‚Üí Output: —Å–∏–Ω–µ–µ –≤–µ–¥—Ä–æ;blue bucket, —Å—Ç–æ–ª;table\
                This format ensures clarity, consistency, and high compatibility with downstream object detection systems.\
                Let me know if you'd like this as a structured JSON response format or used in a live NLP pipeline."},
                {
                    "role": "user",
                    "text": prompt,
                },
            ]
        )

        return result[0].text

    except Exception as e:
        return f"An error occurred: {e}"


def text_to_speach(text: str, output_path: str) -> None:
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

    model = ttsModel(model_name="vosk-model-tts-ru-0.8-multi")

    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤–µ—Å–∞ –Ω–∞ GPU
    model.model = model.model.to(device)

    # –ù–µ–∫–æ—Ç–æ—Ä—ã–µ TTS –º–æ–¥–µ–ª–∏ —Ç—Ä–µ–±—É—é—Ç –ø–µ—Ä–µ–¥–∞—á–∏ device –≤ forward
    synth = Synth(model)
    synth.device = device  # <- –¥–æ–±–∞–≤–∏–º —ç—Ç–æ, –µ—Å–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç ‚Äî –ø–µ—Ä–µ–ø–∏—à–µ–º forward

    synth.synth(f"–ü—Ä–∏–≤–µ—Ç! –°–µ–π—á–∞—Å –Ω–∞–π–¥—É —Ç–µ–±–µ {text[0][0]}!", output_path, speaker_id=2)

    print(f"–û—Ç–≤–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_path}")
