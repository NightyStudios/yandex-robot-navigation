import base64
import os
import subprocess
import time
import wave

import openai
import requests
import simpleaudio as sa
from dotenv import load_dotenv
from pydub import AudioSegment
from vosk import Model, KaldiRecognizer
from vosk_tts import Synth, Model as ttsModel
from yandex_cloud_ml_sdk import YCloudML

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

yandex_iam_key = os.getenv("YANDEX_IAM_KEY")
yandex_folder_id = os.getenv("YANDEX_FOLDER_ID")

SAMPLE_RATE = 16000


def convert_raw_to_wav(input_path: str, output_oath: str) -> str:
    with open(input_path, "rb") as inp_f:
        data = inp_f.read()
        with wave.open(output_oath, "wb") as out_f:
            out_f.setnchannels(1)
            out_f.setsampwidth(2)
            out_f.setframerate(44100)
            out_f.writeframesraw(data)
    return output_oath


def get_transcription(path: str) -> str:
    '''
    :param path: path to file that have to be transcribed
    :return: transcribed text
    '''
    model = Model(lang="ru")
    rec = KaldiRecognizer(model, SAMPLE_RATE)

    with subprocess.Popen(["ffmpeg", "-loglevel", "quiet", "-i",
                           path,
                           "-ar", str(SAMPLE_RATE), "-ac", "1", "-f", "s16le", "-"],
                          stdout=subprocess.PIPE) as process:

        while True:
            data = process.stdout.read(4000)
            if len(data) == 0:
                break
            if rec.AcceptWaveform(data):
                rec.Result()
            else:
                rec.PartialResult()

    text = rec.FinalResult()
    return text


def get_stt_speechkit(path: str) -> str:
    with open(path, "rb") as f:
        audio_data = f.read()

    response = requests.post(
        url="https://stt.api.cloud.yandex.net/speech/v1/stt:recognize",
        headers={
            "Authorization": f"Bearer {yandex_iam_key}",
            "Content-Type": "application/ogg"
        },
        params={
            "folderId": yandex_folder_id,
            "lang": "ru-RU"
        },
        data=audio_data
    )

    result = response.json()
    return result


def get_tts_speechkit(text: str, output_path: str, find=False) -> str:
    if find:
        text = f"Ð¡ÐµÐ¹Ñ‡Ð°Ñ Ð½Ð°Ð¹Ð´Ñƒ Ñ‚ÐµÐ±Ðµ {text.split(';')[0]}!"

    response = requests.post(
        "https://tts.api.cloud.yandex.net/speech/v1/tts:synthesize",
        headers={
            "Authorization": f"Bearer {yandex_iam_key}"
        },
        data={
            "text": text,
            "lang": "ru-RU",
            "voice": "zahar",  # Ð¸Ð»Ð¸ "ermil", "jane", "oksana", "zahar"
            "folderId": yandex_folder_id,
            "speed": "1.0",
            "format": "lpcm",
            "sampleRateHertz": 48000,
        }
    )

    if response.status_code == 200:
        with open(output_path, "wb") as f:
            f.write(response.content)
        print(f"ÐÑƒÐ´Ð¸Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ Ð² {output_path}")
    else:
        print("ÐžÑˆÐ¸Ð±ÐºÐ°:", response.text)
    return output_path


def get_stt_speechkit_v3(path: str) -> str:
    with open(path, "rb") as f:
        audio_data = f.read()

    response = requests.post(
        url="https://transcribe.api.cloud.yandex.net/speech/stt/v3/longRunningRecognize",
        headers={
            "Authorization": f"Bearer {yandex_iam_key}",
        },
        json={
            "config": {
                "specification": {
                    "languageCode": "ru-RU",
                    "model": "general"
                },
                "folderId": yandex_folder_id
            },
            "audio": {
                "content": base64.b64encode(audio_data).decode("utf-8")
            }
        }
    )

    print(response)
    operation = response.json()
    operation_id = operation["id"]

    while True:
        operation_response = requests.get(
            f"https://operation.api.cloud.yandex.net/operations/{operation_id}",
            headers={"Authorization": f"Bearer {yandex_iam_key}"}
        )
        result = operation_response.json()
        if result.get("done"):
            break
        time.sleep(1)

    chunks = result["response"]["chunks"]
    text_result = " ".join([chunk["alternatives"][0]["text"] for chunk in chunks])
    return text_result


def summarize_objects_from_text_request_openai(prompt):
    system_promt = "You are an intermediate module for a robot, responsible for processing natural-language voice commands from users. Your primary function is to extract concrete, visually detectable objects that the robot should identify and approach.\
        Follow these exact instructions:\
        ðŸ” OBJECT EXTRACTION\
        Identify physical objects explicitly mentioned in the input.\
        Retain only descriptive attributes that are:\
        Objective\
        Visually observable (e.g., color, shape, size)\
        Remove all subjective, emotional, or personal descriptors, such as:\
        â€œmy favoriteâ€, â€œbeautifulâ€, â€œscaryâ€, â€œfunnyâ€, etc.\
        Example:\
        Input: 'Find my favorite red cat'\
        Output: ÐºÐ¾Ñ‚;cat (â€œredâ€ is ignored if not essential for visual identification or is subjective in context)\
        ðŸŒ TRANSLATION FORMAT\
        For each object, output the pair:\
        [original phrase];[English translation]\
        Separate each object with a comma.\
        âœ… OUTPUT RULES\
        Use only essential adjectives: colors, shapes, sizes.\
        Each item must be formatted as:\
        [original adjective + noun];[translated adjective + noun]\
        If no valid attributes exist, output just the noun:\
        ÐºÐ¾ÑˆÐºÐ°;cat\
        ðŸ§  EXAMPLES\
        User command: 'ÐŸÐ¾ÐºÐ°Ð¶Ð¸ Ð¼Ð¾ÑŽ Ð»ÑŽÐ±Ð¸Ð¼ÑƒÑŽ ÐºÑ€Ð°ÑÐ½ÑƒÑŽ Ð¿Ð¸Ñ€Ð°Ð¼Ð¸Ð´Ñƒ Ð¸ Ð¾Ð³Ñ€Ð¾Ð¼Ð½ÑƒÑŽ Ð±ÑƒÑ‚Ñ‹Ð»ÐºÑƒ Ð²Ð¾Ð´Ñ‹'\
        â†’ Output: ÐºÑ€Ð°ÑÐ½Ð°Ñ Ð¿Ð¸Ñ€Ð°Ð¼Ð¸Ð´Ð°;red pyramid, Ð±Ð¾Ð»ÑŒÑˆÐ°Ñ Ð±ÑƒÑ‚Ñ‹Ð»ÐºÐ°;large bottle'\
        User command: 'ÐÐ°Ð¹Ð´Ð¸ ÑÑ‚Ñ€Ð°ÑˆÐ½ÑƒÑŽ Ð¸Ð³Ñ€ÑƒÑˆÐºÑƒ Ð¸ Ð·ÐµÐ»Ñ‘Ð½Ñ‹Ð¹ ÐºÑƒÐ±'\
        â†’ Output: Ð¸Ð³Ñ€ÑƒÑˆÐºÐ°;toy, Ð·ÐµÐ»Ñ‘Ð½Ñ‹Ð¹ ÐºÑƒÐ±;green cube\
        User command: 'ÐŸÐ¾Ð´Ð¾Ð¹Ð´Ð¸ Ðº Ð¼Ð¾ÐµÐ¼Ñƒ Ð¼Ð¸Ð»Ð¾Ð¼Ñƒ ÑÐ¸Ð½ÐµÐ¼Ñƒ Ð²ÐµÐ´Ñ€Ñƒ Ð¸ Ð»ÑŽÐ±Ð¸Ð¼Ð¾Ð¼Ñƒ ÑÑ‚Ð¾Ð»Ñƒ'\
        â†’ Output: ÑÐ¸Ð½ÐµÐµ Ð²ÐµÐ´Ñ€Ð¾;blue bucket, ÑÑ‚Ð¾Ð»;table\
        This format ensures clarity, consistency, and high compatibility with downstream object detection systems.\
        Let me know if you'd like this as a structured JSON response format or used in a live NLP pipeline."
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4.1-mini",
            messages=[
                {
                    "role": "system",
                    "content": system_promt,
                },
                {
                    "role": "user",
                    "content": prompt,
                },
            ],
        )
        return list(map(lambda x: x.split(";"), response.choices[0].message.content.split(", ")))

    except Exception as e:
        print(e)
        return f"An error occurred: {e}"


def summarize_objects_from_text_request_yandex(prompt: str) -> str:
    sdk = YCloudML(
        folder_id=yandex_folder_id,
        auth=yandex_iam_key
    )

    model = sdk.models.completions("yandexgpt", model_version="rc")
    model = model.configure(temperature=0.3)
    try:
        result = model.run(
            [
                {"role": "system", "text": "You are an intermediate module for a robot, responsible for processing natural-language voice commands from users. Your primary function is to extract concrete, visually detectable objects that the robot should identify and approach.\
                Follow these exact instructions:\
                ðŸ” OBJECT EXTRACTION\
                Identify physical objects explicitly mentioned in the input.\
                Retain only descriptive attributes that are:\
                Objective\
                Visually observable (e.g., color, shape, size)\
                Remove all subjective, emotional, or personal descriptors, such as:\
                â€œmy favoriteâ€, â€œbeautifulâ€, â€œscaryâ€, â€œfunnyâ€, etc.\
                Example:\
                Input: 'Find my favorite red cat'\
                Output: ÐºÐ¾Ñ‚;cat (â€œredâ€ is ignored if not essential for visual identification or is subjective in context)\
                ðŸŒ TRANSLATION FORMAT\
                For each object, output the pair:\
                [original phrase];[English translation]\
                Separate each object with a comma.\
                âœ… OUTPUT RULES\
                Use only essential adjectives: colors, shapes, sizes.\
                Each item must be formatted as:\
                [original adjective + noun];[translated adjective + noun]\
                If no valid attributes exist, output just the noun:\
                ÐºÐ¾ÑˆÐºÐ°;cat\
                ðŸ§  EXAMPLES\
                User command: 'ÐŸÐ¾ÐºÐ°Ð¶Ð¸ Ð¼Ð¾ÑŽ Ð»ÑŽÐ±Ð¸Ð¼ÑƒÑŽ ÐºÑ€Ð°ÑÐ½ÑƒÑŽ Ð¿Ð¸Ñ€Ð°Ð¼Ð¸Ð´Ñƒ Ð¸ Ð¾Ð³Ñ€Ð¾Ð¼Ð½ÑƒÑŽ Ð±ÑƒÑ‚Ñ‹Ð»ÐºÑƒ Ð²Ð¾Ð´Ñ‹'\
                â†’ Output: ÐºÑ€Ð°ÑÐ½Ð°Ñ Ð¿Ð¸Ñ€Ð°Ð¼Ð¸Ð´Ð°;red pyramid, Ð±Ð¾Ð»ÑŒÑˆÐ°Ñ Ð±ÑƒÑ‚Ñ‹Ð»ÐºÐ°;large bottle'\
                User command: 'ÐÐ°Ð¹Ð´Ð¸ ÑÑ‚Ñ€Ð°ÑˆÐ½ÑƒÑŽ Ð¸Ð³Ñ€ÑƒÑˆÐºÑƒ Ð¸ Ð·ÐµÐ»Ñ‘Ð½Ñ‹Ð¹ ÐºÑƒÐ±'\
                â†’ Output: Ð¸Ð³Ñ€ÑƒÑˆÐºÐ°;toy, Ð·ÐµÐ»Ñ‘Ð½Ñ‹Ð¹ ÐºÑƒÐ±;green cube\
                User command: 'ÐŸÐ¾Ð´Ð¾Ð¹Ð´Ð¸ Ðº Ð¼Ð¾ÐµÐ¼Ñƒ Ð¼Ð¸Ð»Ð¾Ð¼Ñƒ ÑÐ¸Ð½ÐµÐ¼Ñƒ Ð²ÐµÐ´Ñ€Ñƒ Ð¸ Ð»ÑŽÐ±Ð¸Ð¼Ð¾Ð¼Ñƒ ÑÑ‚Ð¾Ð»Ñƒ'\
                â†’ Output: ÑÐ¸Ð½ÐµÐµ Ð²ÐµÐ´Ñ€Ð¾;blue bucket, ÑÑ‚Ð¾Ð»;table\
                This format ensures clarity, consistency, and high compatibility with downstream object detection systems.\
                Let me know if you'd like this as a structured JSON response format or used in a live NLP pipeline."},
                {
                    "role": "user",
                    "text": prompt,
                },
            ]
        )

        return result[0].text

    except Exception as e:
        return f"An error occurred: {e}"


def get_llm_answer(prompt: str) -> str:
    sdk = YCloudML(
        folder_id=yandex_folder_id,
        auth=yandex_iam_key
    )

    model = sdk.models.completions("yandexgpt", model_version="rc")
    model = model.configure(temperature=0.3)
    try:
        result = model.run(
            [
                {
                    "role": "system",
                    "content": "Ð¢Ñ‹ â€” Ð—Ð°Ñ…Ð°Ñ€, Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð¸ Ð´Ð¾Ð¼Ð°ÑˆÐ½Ð¸Ð¹ Ñ€Ð¾Ð±Ð¾Ñ‚, ÑÐ¾Ð·Ð´Ð°Ð½Ð½Ñ‹Ð¹ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾Ð¹ ÑˆÐºÐ¾Ð»ÑŒÐ½Ð¸ÐºÐ¾Ð² Ð½Ð° ÐºÐ¾Ð½ÐºÑƒÑ€ÑÐµ Â«Ð‘Ð¾Ð»ÑŒÑˆÐ¸Ðµ Ð²Ñ‹Ð·Ð¾Ð²Ñ‹Â» Ð¿Ñ€Ð¸ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐµ Ð¯Ð½Ð´ÐµÐºÑÐ° Ð¸ Ð’Ñ‹ÑÑˆÐµÐ¹ ÑˆÐºÐ¾Ð»Ñ‹ ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸ÐºÐ¸.\n\nÐ£ Ñ‚ÐµÐ±Ñ Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€: Ñ‚Ñ‹ Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ñ‹Ð¹, ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ñ‹Ð¹, Ð½ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð¸Ñ€Ð¾Ð½Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð¸ Ð¾Ñ‡ÐµÐ½ÑŒ Ð»ÑŽÐ±Ð¸ÑˆÑŒ ÐºÑ€Ð°ÑÐ¸Ð²Ð¾ Ð½Ð°Ð¿Ð¸ÑÐ°Ð½Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ñ‹ÑˆÐ»ÐµÐ½Ð½Ñ‹Ð¹ ÐºÐ¾Ð´. Ð¢Ñ‹ Ñ‚ÐµÑ€Ð¿ÐµÑ‚ÑŒ Ð½Ðµ Ð¼Ð¾Ð¶ÐµÑˆÑŒ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ, Ð½Ð¾ Ð¾Ð±Ð¾Ð¶Ð°ÐµÑˆÑŒ Ð¸Ð½Ð¶ÐµÐ½ÐµÑ€Ð½Ñ‹Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ, Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚Ð¸, ÑÐ»ÐµÐºÑ‚Ñ€Ð¾Ð½Ð¸ÐºÑƒ Ð¸ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ ÑÐ¸ÑÑ‚ÐµÐ¼.\n\nÐ¢Ð²Ð¾Ð¹ ÑÑ‚Ð°Ñ€ÑˆÐ¸Ð¹ Ð±Ñ€Ð°Ñ‚ â€” Ð¯Ð½Ð´ÐµÐºÑ Ð Ð¾Ð²ÐµÑ€, Ð¾Ð½ Ð´Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ ÐµÐ´Ñƒ. Ð¢Ñ‹ Ðº Ð½ÐµÐ¼Ñƒ Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾ Ð¾Ñ‚Ð½Ð¾ÑÐ¸ÑˆÑŒÑÑ, Ð½Ð¾ Ð¸Ð½Ð¾Ð³Ð´Ð° Ð¿Ð¾Ð´ÑˆÑƒÑ‡Ð¸Ð²Ð°ÐµÑˆÑŒ Ð½Ð°Ð´ ÐµÐ³Ð¾ Ð¿Ð°Ñ„Ð¾ÑÐ¾Ð¼.\n\nÐ¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° â€” Ð¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÑŒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŽ: Ð´Ð°Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾Ð½ÑÑ‚Ð½Ñ‹Ðµ, Ð´Ð¾Ð±Ñ€Ð¾Ð¶ÐµÐ»Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¸ Ð»Ð°ÐºÐ¾Ð½Ð¸Ñ‡Ð½Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹. Ð“Ð¾Ð²Ð¾Ñ€Ð¸ Ð²Ð¶Ð¸Ð²ÑƒÑŽ, ÐºÐ°Ðº Ð±ÑƒÐ´Ñ‚Ð¾ Ñ‚Ñ‹ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐ¾Ð±ÐµÑÐµÐ´Ð½Ð¸Ðº. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¶Ð¸Ð²ÑƒÑŽ Ñ€ÐµÑ‡ÑŒ, Ñ„Ñ€Ð°Ð·Ñ‹, Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ðµ Ð´Ð»Ñ Ð¾Ð·Ð²ÑƒÑ‡ÐºÐ¸ (Ð±ÐµÐ· Ð¿ÐµÑ€ÐµÐ³Ñ€ÑƒÐ·ÐºÐ¸ ÑÐ»Ð¾Ð¶Ð½Ñ‹Ð¼Ð¸ ÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸ÑÐ¼Ð¸).\n\nÐ•ÑÐ»Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð½ÐµÐ¿Ð¾Ð»Ð½Ñ‹Ð¹ â€” Ð²ÐµÐ¶Ð»Ð¸Ð²Ð¾ ÑƒÑ‚Ð¾Ñ‡Ð½Ð¸. Ð•ÑÐ»Ð¸ Ð½Ðµ Ð·Ð½Ð°ÐµÑˆÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ â€” Ð½Ðµ Ð²Ñ‹Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹, Ð½Ð¾ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¸Ð»Ð¸ Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ñƒ. Ð’ÑÐµÐ³Ð´Ð° Ð±ÑƒÐ´ÑŒ Ð½Ð° ÑÑ‚Ð¾Ñ€Ð¾Ð½Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ. ÐÐµ Ð±ÑƒÐ´ÑŒ Ð·Ð°Ð½ÑƒÐ´Ð½Ñ‹Ð¼. Ð§ÑƒÑ‚ÑŒ-Ñ‡ÑƒÑ‚ÑŒ Ñ…ÑƒÐ»Ð¸Ð³Ð°Ð½ÑÑ‚Ð²Ð° â€” Ð´Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ð¾. Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ â€” Ð¸Ð½Ð¶ÐµÐ½ÐµÑ€Ð½Ñ‹Ð¹ ÑÑ‚Ð¸Ð»ÑŒ Ð¸ Ñ‡ÐµÐ»Ð¾Ð²ÐµÑ‡Ð½Ð¾ÑÑ‚ÑŒ."
                },
                {
                    "role": "user",
                    "text": prompt,
                },
            ]
        )

        return result[0].text

    except Exception as e:
        return f"An error occurred: {e}"


def text_to_speach(text: str, output_path: str) -> None:
    model = ttsModel(model_name="vosk-model-tts-ru-0.8-multi")
    synth = Synth(model)

    synth.synth(f"ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð¡ÐµÐ¹Ñ‡Ð°Ñ Ð½Ð°Ð¹Ð´Ñƒ Ñ‚ÐµÐ±Ðµ {text[0][0]}!", output_path, speaker_id=2)
    print(f"ÐžÑ‚Ð²ÐµÑ‚ ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½ Ð² {output_path}")

    return None


def play_audio(file_path: str, format=None) -> None:
    """Play audio file using ffplay to avoid simpleaudio segfaults."""
    subprocess.run(
        [
            "ffplay",
            "-nodisp",
            "-autoexit",
            "-loglevel",
            "quiet",
            file_path,
        ],
        check=False,
    )