import base64
import os
import subprocess
import time
import wave

import openai
import requests
import torch

from dotenv import load_dotenv
from pydub import AudioSegment
from vosk import Model, KaldiRecognizer
from vosk_tts import Synth, Model as ttsModel
from yandex_cloud_ml_sdk import YCloudML

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

yandex_iam_key = os.getenv("YANDEX_IAM_KEY")
yandex_folder_id = os.getenv("YANDEX_FOLDER_ID")

SAMPLE_RATE = 16000


def convert_raw_to_wav(input_path: str, output_oath: str) -> str:
    with open(input_path, "rb") as inp_f:
        data = inp_f.read()
        with wave.open(output_oath, "wb") as out_f:
            out_f.setnchannels(1)
            out_f.setsampwidth(2)
            out_f.setframerate(44100)
            out_f.writeframesraw(data)
    return output_oath


def get_transcription(path: str) -> str:
    '''
    :param path: path to file that have to be transcribed
    :return: transcribed text
    '''
    model = Model(lang="ru")
    rec = KaldiRecognizer(model, SAMPLE_RATE)

    with subprocess.Popen(["ffmpeg", "-loglevel", "quiet", "-i",
                           path,
                           "-ar", str(SAMPLE_RATE), "-ac", "1", "-f", "s16le", "-"],
                          stdout=subprocess.PIPE) as process:

        while True:
            data = process.stdout.read(4000)
            if len(data) == 0:
                break
            if rec.AcceptWaveform(data):
                rec.Result()
            else:
                rec.PartialResult()

    text = rec.FinalResult()
    return text


def get_stt_speechkit(path: str) -> str:
    with open(path, "rb") as f:
        audio_data = f.read()

    response = requests.post(
        url="https://stt.api.cloud.yandex.net/speech/v1/stt:recognize",
        headers={
            "Authorization": f"Bearer {yandex_iam_key}",
            "Content-Type": "application/ogg"
        },
        params={
            "folderId": yandex_folder_id,
            "lang": "ru-RU"
        },
        data=audio_data
    )

    result = response.json()
    return result


def get_tts_speechkit(text: str, output_path: str) -> str:
    text = f"–ü—Ä–∏–≤–µ—Ç! –°–µ–π—á–∞—Å –Ω–∞–π–¥—É —Ç–µ–±–µ {text.split(';')[0]}!"

    response = requests.post(
        "https://tts.api.cloud.yandex.net/speech/v1/tts:synthesize",
        headers={
            "Authorization": f"Bearer {yandex_iam_key}"
        },
        data={
            "text": text,
            "lang": "ru-RU",
            "voice": "zahar",  # –∏–ª–∏ "ermil", "jane", "oksana", "zahar"
            "folderId": yandex_folder_id,
            "speed": "1.0",
            "format": "lpcm",
            "sampleRateHertz": 48000,
        }
    )

    if response.status_code == 200:
        with open(output_path, "wb") as f:
            f.write(response.content)
        print(f"–ê—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {output_path}")
    else:
        print("–û—à–∏–±–∫–∞:", response.text)
    return output_path


def get_stt_speechkit_v3(path: str) -> str:
    with open(path, "rb") as f:
        audio_data = f.read()

    response = requests.post(
        url="https://transcribe.api.cloud.yandex.net/speech/stt/v3/longRunningRecognize",
        headers={
            "Authorization": f"Bearer {yandex_iam_key}",
        },
        json={
            "config": {
                "specification": {
                    "languageCode": "ru-RU",
                    "model": "general"
                },
                "folderId": yandex_folder_id
            },
            "audio": {
                "content": base64.b64encode(audio_data).decode("utf-8")
            }
        }
    )

    print(response)
    operation = response.json()
    operation_id = operation["id"]

    while True:
        operation_response = requests.get(
            f"https://operation.api.cloud.yandex.net/operations/{operation_id}",
            headers={"Authorization": f"Bearer {yandex_iam_key}"}
        )
        result = operation_response.json()
        if result.get("done"):
            break
        time.sleep(1)

    chunks = result["response"]["chunks"]
    text_result = " ".join([chunk["alternatives"][0]["text"] for chunk in chunks])
    return text_result

def summarize_objects_from_text_request_openai(prompt):
    system_promt = "You are an intermediate module for a robot, responsible for processing natural-language voice commands from users. Your primary function is to extract concrete, visually detectable objects that the robot should identify and approach.\
        Follow these exact instructions:\
        üîç OBJECT EXTRACTION\
        Identify physical objects explicitly mentioned in the input.\
        Retain only descriptive attributes that are:\
        Objective\
        Visually observable (e.g., color, shape, size)\
        Remove all subjective, emotional, or personal descriptors, such as:\
        ‚Äúmy favorite‚Äù, ‚Äúbeautiful‚Äù, ‚Äúscary‚Äù, ‚Äúfunny‚Äù, etc.\
        Example:\
        Input: 'Find my favorite red cat'\
        Output: –∫–æ—Ç;cat (‚Äúred‚Äù is ignored if not essential for visual identification or is subjective in context)\
        üåê TRANSLATION FORMAT\
        For each object, output the pair:\
        [original phrase];[English translation]\
        Separate each object with a comma.\
        ‚úÖ OUTPUT RULES\
        Use only essential adjectives: colors, shapes, sizes.\
        Each item must be formatted as:\
        [original adjective + noun];[translated adjective + noun]\
        If no valid attributes exist, output just the noun:\
        –∫–æ—à–∫–∞;cat\
        üß† EXAMPLES\
        User command: '–ü–æ–∫–∞–∂–∏ –º–æ—é –ª—é–±–∏–º—É—é –∫—Ä–∞—Å–Ω—É—é –ø–∏—Ä–∞–º–∏–¥—É –∏ –æ–≥—Ä–æ–º–Ω—É—é –±—É—Ç—ã–ª–∫—É –≤–æ–¥—ã'\
        ‚Üí Output: –∫—Ä–∞—Å–Ω–∞—è –ø–∏—Ä–∞–º–∏–¥–∞;red pyramid, –±–æ–ª—å—à–∞—è –±—É—Ç—ã–ª–∫–∞;large bottle'\
        User command: '–ù–∞–π–¥–∏ —Å—Ç—Ä–∞—à–Ω—É—é –∏–≥—Ä—É—à–∫—É –∏ –∑–µ–ª—ë–Ω—ã–π –∫—É–±'\
        ‚Üí Output: –∏–≥—Ä—É—à–∫–∞;toy, –∑–µ–ª—ë–Ω—ã–π –∫—É–±;green cube\
        User command: '–ü–æ–¥–æ–π–¥–∏ –∫ –º–æ–µ–º—É –º–∏–ª–æ–º—É —Å–∏–Ω–µ–º—É –≤–µ–¥—Ä—É –∏ –ª—é–±–∏–º–æ–º—É —Å—Ç–æ–ª—É'\
        ‚Üí Output: —Å–∏–Ω–µ–µ –≤–µ–¥—Ä–æ;blue bucket, —Å—Ç–æ–ª;table\
        This format ensures clarity, consistency, and high compatibility with downstream object detection systems.\
        Let me know if you'd like this as a structured JSON response format or used in a live NLP pipeline."
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4.1-mini",
            messages=[
                {
                    "role": "system",
                    "content": system_promt,
                },
                {
                    "role": "user",
                    "content": prompt,
                },
            ],
        )
        return list(map(lambda x: x.split(";"), response.choices[0].message.content.split(", ")))

    except Exception as e:
        print(e)
        return f"An error occurred: {e}"


def summarize_objects_from_text_request_yandex(prompt: str) -> str:
    sdk = YCloudML(
        folder_id=yandex_folder_id,
        auth=yandex_iam_key
    )

    model = sdk.models.completions("yandexgpt", model_version="rc")
    model = model.configure(temperature=0.3)
    try:
        result = model.run(
            [
                {"role": "system", "text": "You are an intermediate module for a robot, responsible for processing natural-language voice commands from users. Your primary function is to extract concrete, visually detectable objects that the robot should identify and approach.\
                Follow these exact instructions:\
                üîç OBJECT EXTRACTION\
                Identify physical objects explicitly mentioned in the input.\
                Retain only descriptive attributes that are:\
                Objective\
                Visually observable (e.g., color, shape, size)\
                Remove all subjective, emotional, or personal descriptors, such as:\
                ‚Äúmy favorite‚Äù, ‚Äúbeautiful‚Äù, ‚Äúscary‚Äù, ‚Äúfunny‚Äù, etc.\
                Example:\
                Input: 'Find my favorite red cat'\
                Output: –∫–æ—Ç;cat (‚Äúred‚Äù is ignored if not essential for visual identification or is subjective in context)\
                üåê TRANSLATION FORMAT\
                For each object, output the pair:\
                [original phrase];[English translation]\
                Separate each object with a comma.\
                ‚úÖ OUTPUT RULES\
                Use only essential adjectives: colors, shapes, sizes.\
                Each item must be formatted as:\
                [original adjective + noun];[translated adjective + noun]\
                If no valid attributes exist, output just the noun:\
                –∫–æ—à–∫–∞;cat\
                üß† EXAMPLES\
                User command: '–ü–æ–∫–∞–∂–∏ –º–æ—é –ª—é–±–∏–º—É—é –∫—Ä–∞—Å–Ω—É—é –ø–∏—Ä–∞–º–∏–¥—É –∏ –æ–≥—Ä–æ–º–Ω—É—é –±—É—Ç—ã–ª–∫—É –≤–æ–¥—ã'\
                ‚Üí Output: –∫—Ä–∞—Å–Ω–∞—è –ø–∏—Ä–∞–º–∏–¥–∞;red pyramid, –±–æ–ª—å—à–∞—è –±—É—Ç—ã–ª–∫–∞;large bottle'\
                User command: '–ù–∞–π–¥–∏ —Å—Ç—Ä–∞—à–Ω—É—é –∏–≥—Ä—É—à–∫—É –∏ –∑–µ–ª—ë–Ω—ã–π –∫—É–±'\
                ‚Üí Output: –∏–≥—Ä—É—à–∫–∞;toy, –∑–µ–ª—ë–Ω—ã–π –∫—É–±;green cube\
                User command: '–ü–æ–¥–æ–π–¥–∏ –∫ –º–æ–µ–º—É –º–∏–ª–æ–º—É —Å–∏–Ω–µ–º—É –≤–µ–¥—Ä—É –∏ –ª—é–±–∏–º–æ–º—É —Å—Ç–æ–ª—É'\
                ‚Üí Output: —Å–∏–Ω–µ–µ –≤–µ–¥—Ä–æ;blue bucket, —Å—Ç–æ–ª;table\
                This format ensures clarity, consistency, and high compatibility with downstream object detection systems.\
                Let me know if you'd like this as a structured JSON response format or used in a live NLP pipeline."},
                {
                    "role": "user",
                    "text": prompt,
                },
            ]
        )

        return result[0].text

    except Exception as e:
        return f"An error occurred: {e}"


def text_to_speach(text: str, output_path: str) -> None:
    model = ttsModel(model_name="vosk-model-tts-ru-0.8-multi")
    synth = Synth(model)

    synth.synth(f"–ü—Ä–∏–≤–µ—Ç! –°–µ–π—á–∞—Å –Ω–∞–π–¥—É —Ç–µ–±–µ {text[0][0]}!", output_path, speaker_id=2)
    print(f"–û—Ç–≤–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_path}")

    return None