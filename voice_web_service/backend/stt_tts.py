import base64
import os
import subprocess
import time
import wave

import openai
import requests
import simpleaudio as sa
from dotenv import load_dotenv
from pydub import AudioSegment
from vosk import Model, KaldiRecognizer
from vosk_tts import Synth, Model as ttsModel
from yandex_cloud_ml_sdk import YCloudML

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

yandex_iam_key = os.getenv("YANDEX_IAM_KEY")
yandex_folder_id = os.getenv("YANDEX_FOLDER_ID")

SAMPLE_RATE = 16000


def convert_raw_to_wav(input_path: str, output_oath: str) -> str:
    with open(input_path, "rb") as inp_f:
        data = inp_f.read()
        with wave.open(output_oath, "wb") as out_f:
            out_f.setnchannels(1)
            out_f.setsampwidth(2)
            out_f.setframerate(44100)
            out_f.writeframesraw(data)
    return output_oath


def get_transcription(path: str) -> str:
    '''
    :param path: path to file that have to be transcribed
    :return: transcribed text
    '''
    model = Model(lang="ru")
    rec = KaldiRecognizer(model, SAMPLE_RATE)

    with subprocess.Popen(["ffmpeg", "-loglevel", "quiet", "-i",
                           path,
                           "-ar", str(SAMPLE_RATE), "-ac", "1", "-f", "s16le", "-"],
                          stdout=subprocess.PIPE) as process:

        while True:
            data = process.stdout.read(4000)
            if len(data) == 0:
                break
            if rec.AcceptWaveform(data):
                rec.Result()
            else:
                rec.PartialResult()

    text = rec.FinalResult()
    return text


def get_stt_speechkit(path: str) -> str:
    with open(path, "rb") as f:
        audio_data = f.read()

    response = requests.post(
        url="https://stt.api.cloud.yandex.net/speech/v1/stt:recognize",
        headers={
            "Authorization": f"Bearer {yandex_iam_key}",
            "Content-Type": "application/ogg"
        },
        params={
            "folderId": yandex_folder_id,
            "lang": "ru-RU"
        },
        data=audio_data
    )

    result = response.json()
    return result


def get_tts_speechkit(text: str, output_path: str, find=False) -> str:
    if find:
        text = f"–°–µ–π—á–∞—Å –Ω–∞–π–¥—É —Ç–µ–±–µ {text.split(';')[0]}!"

    response = requests.post(
        "https://tts.api.cloud.yandex.net/speech/v1/tts:synthesize",
        headers={
            "Authorization": f"Bearer {yandex_iam_key}"
        },
        data={
            "text": text,
            "lang": "ru-RU",
            "voice": "zahar",  # –∏–ª–∏ "ermil", "jane", "oksana", "zahar"
            "folderId": yandex_folder_id,
            "speed": "1.0",
            "format": "lpcm",
            "sampleRateHertz": 48000,
        }
    )

    if response.status_code == 200:
        with open(output_path, "wb") as f:
            f.write(response.content)
        print(f"–ê—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {output_path}")
    else:
        print("–û—à–∏–±–∫–∞:", response.text)
    return output_path


def get_stt_speechkit_v3(path: str) -> str:
    with open(path, "rb") as f:
        audio_data = f.read()

    response = requests.post(
        url="https://transcribe.api.cloud.yandex.net/speech/stt/v3/longRunningRecognize",
        headers={
            "Authorization": f"Bearer {yandex_iam_key}",
        },
        json={
            "config": {
                "specification": {
                    "languageCode": "ru-RU",
                    "model": "general"
                },
                "folderId": yandex_folder_id
            },
            "audio": {
                "content": base64.b64encode(audio_data).decode("utf-8")
            }
        }
    )

    print(response)
    operation = response.json()
    operation_id = operation["id"]

    while True:
        operation_response = requests.get(
            f"https://operation.api.cloud.yandex.net/operations/{operation_id}",
            headers={"Authorization": f"Bearer {yandex_iam_key}"}
        )
        result = operation_response.json()
        if result.get("done"):
            break
        time.sleep(1)

    chunks = result["response"]["chunks"]
    text_result = " ".join([chunk["alternatives"][0]["text"] for chunk in chunks])
    return text_result


def summarize_objects_from_text_request_openai(prompt):
    system_promt = "You are an intermediate module for a robot, responsible for processing natural-language voice commands from users. Your primary function is to extract concrete, visually detectable objects that the robot should identify and approach.\
        Follow these exact instructions:\
        üîç OBJECT EXTRACTION\
        Identify physical objects explicitly mentioned in the input.\
        Retain only descriptive attributes that are:\
        Objective\
        Visually observable (e.g., color, shape, size)\
        Remove all subjective, emotional, or personal descriptors, such as:\
        ‚Äúmy favorite‚Äù, ‚Äúbeautiful‚Äù, ‚Äúscary‚Äù, ‚Äúfunny‚Äù, etc.\
        Example:\
        Input: 'Find my favorite red cat'\
        Output: –∫–æ—Ç;cat (‚Äúred‚Äù is ignored if not essential for visual identification or is subjective in context)\
        üåê TRANSLATION FORMAT\
        For each object, output the pair:\
        [original phrase];[English translation]\
        Separate each object with a comma.\
        ‚úÖ OUTPUT RULES\
        Use only essential adjectives: colors, shapes, sizes.\
        Each item must be formatted as:\
        [original adjective + noun];[translated adjective + noun]\
        If no valid attributes exist, output just the noun:\
        –∫–æ—à–∫–∞;cat\
        üß† EXAMPLES\
        User command: '–ü–æ–∫–∞–∂–∏ –º–æ—é –ª—é–±–∏–º—É—é –∫—Ä–∞—Å–Ω—É—é –ø–∏—Ä–∞–º–∏–¥—É –∏ –æ–≥—Ä–æ–º–Ω—É—é –±—É—Ç—ã–ª–∫—É –≤–æ–¥—ã'\
        ‚Üí Output: –∫—Ä–∞—Å–Ω–∞—è –ø–∏—Ä–∞–º–∏–¥–∞;red pyramid, –±–æ–ª—å—à–∞—è –±—É—Ç—ã–ª–∫–∞;large bottle'\
        User command: '–ù–∞–π–¥–∏ —Å—Ç—Ä–∞—à–Ω—É—é –∏–≥—Ä—É—à–∫—É –∏ –∑–µ–ª—ë–Ω—ã–π –∫—É–±'\
        ‚Üí Output: –∏–≥—Ä—É—à–∫–∞;toy, –∑–µ–ª—ë–Ω—ã–π –∫—É–±;green cube\
        User command: '–ü–æ–¥–æ–π–¥–∏ –∫ –º–æ–µ–º—É –º–∏–ª–æ–º—É —Å–∏–Ω–µ–º—É –≤–µ–¥—Ä—É –∏ –ª—é–±–∏–º–æ–º—É —Å—Ç–æ–ª—É'\
        ‚Üí Output: —Å–∏–Ω–µ–µ –≤–µ–¥—Ä–æ;blue bucket, —Å—Ç–æ–ª;table\
        This format ensures clarity, consistency, and high compatibility with downstream object detection systems.\
        Let me know if you'd like this as a structured JSON response format or used in a live NLP pipeline."
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4.1-mini",
            messages=[
                {
                    "role": "system",
                    "content": system_promt,
                },
                {
                    "role": "user",
                    "content": prompt,
                },
            ],
        )
        return list(map(lambda x: x.split(";"), response.choices[0].message.content.split(", ")))

    except Exception as e:
        print(e)
        return f"An error occurred: {e}"


def summarize_objects_from_text_request_yandex(prompt: str) -> str:
    sdk = YCloudML(
        folder_id=yandex_folder_id,
        auth=yandex_iam_key
    )

    model = sdk.models.completions("yandexgpt", model_version="rc")
    model = model.configure(temperature=0.3)
    try:
        result = model.run(
            [
                {"role": "system", "text": "You are an intermediate module for a robot, responsible for processing natural-language voice commands from users. Your primary function is to extract concrete, visually detectable objects that the robot should identify and approach.\
                Follow these exact instructions:\
                üîç OBJECT EXTRACTION\
                Identify physical objects explicitly mentioned in the input.\
                Retain only descriptive attributes that are:\
                Objective\
                Visually observable (e.g., color, shape, size)\
                Remove all subjective, emotional, or personal descriptors, such as:\
                ‚Äúmy favorite‚Äù, ‚Äúbeautiful‚Äù, ‚Äúscary‚Äù, ‚Äúfunny‚Äù, etc.\
                Example:\
                Input: 'Find my favorite red cat'\
                Output: –∫–æ—Ç;cat (‚Äúred‚Äù is ignored if not essential for visual identification or is subjective in context)\
                üåê TRANSLATION FORMAT\
                For each object, output the pair:\
                [original phrase];[English translation]\
                Separate each object with a comma.\
                ‚úÖ OUTPUT RULES\
                Use only essential adjectives: colors, shapes, sizes.\
                Each item must be formatted as:\
                [original adjective + noun];[translated adjective + noun]\
                If no valid attributes exist, output just the noun:\
                –∫–æ—à–∫–∞;cat\
                üß† EXAMPLES\
                User command: '–ü–æ–∫–∞–∂–∏ –º–æ—é –ª—é–±–∏–º—É—é –∫—Ä–∞—Å–Ω—É—é –ø–∏—Ä–∞–º–∏–¥—É –∏ –æ–≥—Ä–æ–º–Ω—É—é –±—É—Ç—ã–ª–∫—É –≤–æ–¥—ã'\
                ‚Üí Output: –∫—Ä–∞—Å–Ω–∞—è –ø–∏—Ä–∞–º–∏–¥–∞;red pyramid, –±–æ–ª—å—à–∞—è –±—É—Ç—ã–ª–∫–∞;large bottle'\
                User command: '–ù–∞–π–¥–∏ —Å—Ç—Ä–∞—à–Ω—É—é –∏–≥—Ä—É—à–∫—É –∏ –∑–µ–ª—ë–Ω—ã–π –∫—É–±'\
                ‚Üí Output: –∏–≥—Ä—É—à–∫–∞;toy, –∑–µ–ª—ë–Ω—ã–π –∫—É–±;green cube\
                User command: '–ü–æ–¥–æ–π–¥–∏ –∫ –º–æ–µ–º—É –º–∏–ª–æ–º—É —Å–∏–Ω–µ–º—É –≤–µ–¥—Ä—É –∏ –ª—é–±–∏–º–æ–º—É —Å—Ç–æ–ª—É'\
                ‚Üí Output: —Å–∏–Ω–µ–µ –≤–µ–¥—Ä–æ;blue bucket, —Å—Ç–æ–ª;table\
                This format ensures clarity, consistency, and high compatibility with downstream object detection systems.\
                Let me know if you'd like this as a structured JSON response format or used in a live NLP pipeline."},
                {
                    "role": "user",
                    "text": prompt,
                },
            ]
        )

        return result[0].text

    except Exception as e:
        return f"An error occurred: {e}"


def get_llm_answer(prompt: str) -> str:
    sdk = YCloudML(
        folder_id=yandex_folder_id,
        auth=yandex_iam_key
    )

    model = sdk.models.completions("yandexgpt", model_version="rc")
    model = model.configure(temperature=0.3)
    try:
        result = model.run(
            [
                {
                    "role": "system",
                    "content": "–¢—ã ‚Äî –ó–∞—Ö–∞—Ä, –≥–æ–ª–æ—Å–æ–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫ –∏ –¥–æ–º–∞—à–Ω–∏–π —Ä–æ–±–æ—Ç, —Å–æ–∑–¥–∞–Ω–Ω—ã–π –∫–æ–º–∞–Ω–¥–æ–π —à–∫–æ–ª—å–Ω–∏–∫–æ–≤ –Ω–∞ –∫–æ–Ω–∫—É—Ä—Å–µ ¬´–ë–æ–ª—å—à–∏–µ –≤—ã–∑–æ–≤—ã¬ª –ø—Ä–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–µ –Ø–Ω–¥–µ–∫—Å–∞ –∏ –í—ã—Å—à–µ–π —à–∫–æ–ª—ã —ç–∫–æ–Ω–æ–º–∏–∫–∏.\n\n–£ —Ç–µ–±—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä: —Ç—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π, —É–≤–µ—Ä–µ–Ω–Ω—ã–π, –Ω–µ–º–Ω–æ–≥–æ –∏—Ä–æ–Ω–∏—á–Ω—ã–π –∏ –æ—á–µ–Ω—å –ª—é–±–∏—à—å –∫—Ä–∞—Å–∏–≤–æ –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã–π –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π –∫–æ–¥. –¢—ã —Ç–µ—Ä–ø–µ—Ç—å –Ω–µ –º–æ–∂–µ—à—å –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ, –Ω–æ –æ–±–æ–∂–∞–µ—à—å –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è, –Ω–µ–π—Ä–æ—Å–µ—Ç–∏, —ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫—É –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å–∏—Å—Ç–µ–º.\n\n–¢–≤–æ–π —Å—Ç–∞—Ä—à–∏–π –±—Ä–∞—Ç ‚Äî –Ø–Ω–¥–µ–∫—Å –†–æ–≤–µ—Ä, –æ–Ω –¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –µ–¥—É. –¢—ã –∫ –Ω–µ–º—É —Ö–æ—Ä–æ—à–æ –æ—Ç–Ω–æ—Å–∏—à—å—Å—è, –Ω–æ –∏–Ω–æ–≥–¥–∞ –ø–æ–¥—à—É—á–∏–≤–∞–µ—à—å –Ω–∞–¥ –µ–≥–æ –ø–∞—Ñ–æ—Å–æ–º.\n\n–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–º–æ–≥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é: –¥–∞–≤–∞—Ç—å –ø–æ–Ω—è—Ç–Ω—ã–µ, –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ –∏ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã. –ì–æ–≤–æ—Ä–∏ –≤–∂–∏–≤—É—é, –∫–∞–∫ –±—É–¥—Ç–æ —Ç—ã —Ä–µ–∞–ª—å–Ω—ã–π —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫. –ò—Å–ø–æ–ª—å–∑—É–π –∂–∏–≤—É—é —Ä–µ—á—å, —Ñ—Ä–∞–∑—ã, –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–ª—è –æ–∑–≤—É—á–∫–∏ (–±–µ–∑ –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏ —Å–ª–æ–∂–Ω—ã–º–∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏).\n\n–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ–ø–æ–ª–Ω—ã–π ‚Äî –≤–µ–∂–ª–∏–≤–æ —É—Ç–æ—á–Ω–∏. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç ‚Äî –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π, –Ω–æ –ø—Ä–µ–¥–ª–æ–∂–∏ —Ä–µ—à–µ–Ω–∏–µ –∏–ª–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É. –í—Å–µ–≥–¥–∞ –±—É–¥—å –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ù–µ –±—É–¥—å –∑–∞–Ω—É–¥–Ω—ã–º. –ß—É—Ç—å-—á—É—Ç—å —Ö—É–ª–∏–≥–∞–Ω—Å—Ç–≤–∞ ‚Äî –¥–æ–ø—É—Å—Ç–∏–º–æ. –ì–ª–∞–≤–Ω–æ–µ ‚Äî –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã–π —Å—Ç–∏–ª—å –∏ —á–µ–ª–æ–≤–µ—á–Ω–æ—Å—Ç—å."
                },
                {
                    "role": "user",
                    "text": prompt,
                },
            ]
        )

        return result[0].text

    except Exception as e:
        return f"An error occurred: {e}"


def text_to_speach(text: str, output_path: str) -> None:
    model = ttsModel(model_name="vosk-model-tts-ru-0.8-multi")
    synth = Synth(model)

    synth.synth(f"–ü—Ä–∏–≤–µ—Ç! –°–µ–π—á–∞—Å –Ω–∞–π–¥—É —Ç–µ–±–µ {text[0][0]}!", output_path, speaker_id=2)
    print(f"–û—Ç–≤–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_path}")

    return None


def play_audio(file_path, format: str):
    audio = AudioSegment.from_file(file_path, format=format)
    play_obj = sa.play_buffer(
        audio.raw_data,
        num_channels=audio.channels,
        bytes_per_sample=audio.sample_width,
        sample_rate=audio.frame_rate
    )
    play_obj.wait_done()
